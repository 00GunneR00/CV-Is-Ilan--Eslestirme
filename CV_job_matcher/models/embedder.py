"""
NLP Pipeline ModÃ¼lÃ¼
Transformers (BERT) kullanarak metin embedding'leri oluÅŸturur.
"""

import numpy as np
import torch
from sentence_transformers import SentenceTransformer
from typing import List, Union
import pandas as pd
from tqdm import tqdm


class TextEmbedder:
    """BERT tabanlÄ± metin embedding sÄ±nÄ±fÄ±"""
    
    def __init__(self, model_name: str = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"):
        """
        Args:
            model_name: KullanÄ±lacak sentence transformer modeli
                       TÃ¼rkÃ§e desteÄŸi iÃ§in multilingual model kullanÄ±yoruz
        """
        print(f"ğŸ“¦ Model yÃ¼kleniyor: {model_name}")
        self.model = SentenceTransformer(model_name)
        self.embedding_dim = self.model.get_sentence_embedding_dimension()
        print(f"âœ“ Model yÃ¼klendi. Embedding boyutu: {self.embedding_dim}")
        
        # GPU varsa kullan
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = self.model.to(self.device)
        print(f"âœ“ Cihaz: {self.device}")
    
    def encode_texts(self, texts: Union[List[str], pd.Series], 
                     batch_size: int = 32,
                     show_progress: bool = True) -> np.ndarray:
        """
        Metin listesini embedding vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
        
        Args:
            texts: Embedding'i alÄ±nacak metinler
            batch_size: Batch boyutu (bÃ¼yÃ¼k veriler iÃ§in)
            show_progress: Ä°lerleme Ã§ubuÄŸu gÃ¶ster
            
        Returns:
            (n_samples, embedding_dim) boyutunda numpy array
        """
        if isinstance(texts, pd.Series):
            texts = texts.tolist()
        
        # BoÅŸ veya None deÄŸerleri temizle
        texts = [str(t) if t is not None else "" for t in texts]
        
        print(f"ğŸ”„ {len(texts)} metin vektÃ¶rleÅŸtiriliyor...")
        
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=show_progress,
            convert_to_numpy=True,
            normalize_embeddings=True  # KosinÃ¼s benzerliÄŸi iÃ§in normalize et
        )
        
        print(f"âœ“ VektÃ¶rleÅŸtirme tamamlandÄ±. Shape: {embeddings.shape}")
        return embeddings
    
    def encode_single(self, text: str) -> np.ndarray:
        """
        Tek bir metni vektÃ¶rleÅŸtirir
        
        Args:
            text: VektÃ¶rleÅŸtirilerek metin
            
        Returns:
            (embedding_dim,) boyutunda numpy array
        """
        embedding = self.model.encode(
            [str(text)],
            convert_to_numpy=True,
            normalize_embeddings=True
        )
        return embedding[0]
    
    def prepare_job_embeddings(self, job_df: pd.DataFrame,
                               text_columns: List[str] = None) -> np.ndarray:
        """
        Ä°ÅŸ ilanÄ± DataFrame'inden embedding'ler oluÅŸturur
        
        Args:
            job_df: Ä°ÅŸ ilanlarÄ± DataFrame'i
            text_columns: BirleÅŸtirilecek metin sÃ¼tunlarÄ±
            
        Returns:
            Ä°ÅŸ ilanÄ± embedding'leri
        """
        if text_columns is None:
            text_columns = ['title', 'description', 'required_skills']
        
        print(f"ğŸ“„ Ä°ÅŸ ilanlarÄ± iÃ§in metin hazÄ±rlanÄ±yor...")
        
        # TÃ¼m text sÃ¼tunlarÄ±nÄ± birleÅŸtir
        combined_texts = []
        for _, row in job_df.iterrows():
            text_parts = []
            for col in text_columns:
                if col in job_df.columns and pd.notna(row[col]):
                    text_parts.append(str(row[col]))
            combined_text = " | ".join(text_parts)
            combined_texts.append(combined_text)
        
        return self.encode_texts(combined_texts)
    
    def prepare_cv_embeddings(self, cv_df: pd.DataFrame,
                             text_column: str = 'cv_text') -> np.ndarray:
        """
        CV DataFrame'inden embedding'ler oluÅŸturur
        
        Args:
            cv_df: CV DataFrame'i
            text_column: CV metni sÃ¼tunu
            
        Returns:
            CV embedding'leri
        """
        print(f"ğŸ“„ CV'ler iÃ§in metin hazÄ±rlanÄ±yor...")
        
        if text_column not in cv_df.columns:
            raise ValueError(f"'{text_column}' sÃ¼tunu bulunamadÄ±!")
        
        cv_texts = cv_df[text_column].tolist()
        return self.encode_texts(cv_texts)
    
    def get_embedding_dim(self) -> int:
        """Embedding boyutunu dÃ¶ndÃ¼rÃ¼r"""
        return self.embedding_dim


class EmbeddingCache:
    """Embedding'leri Ã¶nbelleÄŸe alma ve yÃ¼kleme sÄ±nÄ±fÄ±"""
    
    @staticmethod
    def save_embeddings(embeddings: np.ndarray, filepath: str):
        """Embedding'leri kaydet"""
        np.save(filepath, embeddings)
        print(f"âœ“ Embedding'ler kaydedildi: {filepath}")
    
    @staticmethod
    def load_embeddings(filepath: str) -> np.ndarray:
        """Embedding'leri yÃ¼kle"""
        embeddings = np.load(filepath)
        print(f"âœ“ Embedding'ler yÃ¼klendi: {filepath} - Shape: {embeddings.shape}")
        return embeddings
    
    @staticmethod
    def embeddings_exist(filepath: str) -> bool:
        """Embedding dosyasÄ± var mÄ± kontrol et"""
        import os
        return os.path.exists(filepath)


if __name__ == "__main__":
    # Test iÃ§in
    print("=" * 60)
    print("NLP Pipeline Test")
    print("=" * 60)
    
    # Embedder oluÅŸtur
    embedder = TextEmbedder()
    
    # Test metinleri
    test_texts = [
        "Python ve Machine Learning deneyimi olan Senior Data Scientist arÄ±yoruz",
        "5 yÄ±llÄ±k Python, TensorFlow ve NLP deneyimim var",
        "JavaScript ve React ile frontend geliÅŸtirme yapabilecek developer aranÄ±yor"
    ]
    
    print("\nğŸ“ Test metinleri vektÃ¶rleÅŸtiriliyor...")
    embeddings = embedder.encode_texts(test_texts, show_progress=False)
    
    print(f"\nâœ“ Embedding shape: {embeddings.shape}")
    print(f"âœ“ Embedding boyutu: {embedder.get_embedding_dim()}")
    
    # KosinÃ¼s benzerliÄŸi hesapla
    from sklearn.metrics.pairwise import cosine_similarity
    similarities = cosine_similarity(embeddings)
    
    print("\nğŸ“Š KosinÃ¼s Benzerlik Matrisi:")
    print(similarities)
    
    print(f"\nâœ“ Text 1 ve Text 2 benzerliÄŸi: {similarities[0, 1]:.4f}")
    print(f"âœ“ Text 1 ve Text 3 benzerliÄŸi: {similarities[0, 2]:.4f}")