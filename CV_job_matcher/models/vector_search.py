"""
Faiss VektÃ¶r Arama ModÃ¼lÃ¼
YÃ¼ksek performanslÄ± benzerlik aramasÄ± iÃ§in Faiss kullanÄ±r.
"""

import numpy as np
import faiss
import pickle
from typing import Tuple, List, Dict
import os


class FaissVectorSearch:
    """Faiss kullanarak vektÃ¶r benzerlik aramasÄ± yapan sÄ±nÄ±f"""
    
    def __init__(self, embedding_dim: int):
        """
        Args:
            embedding_dim: VektÃ¶r boyutu
        """
        self.embedding_dim = embedding_dim
        self.index = None
        self.is_trained = False
        print(f"ğŸ”§ Faiss arama motoru baÅŸlatÄ±ldÄ± (dim={embedding_dim})")
    
    def build_index(self, embeddings: np.ndarray, index_type: str = "flatl2"):
        """
        Faiss indeksini oluÅŸturur
        
        Args:
            embeddings: (n_samples, embedding_dim) boyutunda embedding matrisi
            index_type: Ä°ndeks tipi
                - "flatl2": Exact search, L2 distance (kÃ¼Ã§Ã¼k-orta veri setleri iÃ§in)
                - "flatip": Exact search, Inner Product (normalize edilmiÅŸ vektÃ¶rler iÃ§in)
                - "ivf": Approximate search (bÃ¼yÃ¼k veri setleri iÃ§in)
        """
        n_samples, dim = embeddings.shape
        
        if dim != self.embedding_dim:
            raise ValueError(
                f"Embedding boyutu uyuÅŸmuyor! Beklenen: {self.embedding_dim}, "
                f"Gelen: {dim}"
            )
        
        print(f"ğŸ—ï¸  Faiss indeksi oluÅŸturuluyor...")
        print(f"   - Veri sayÄ±sÄ±: {n_samples}")
        print(f"   - VektÃ¶r boyutu: {dim}")
        print(f"   - Ä°ndeks tipi: {index_type}")
        
        # VektÃ¶rleri float32'ye dÃ¶nÃ¼ÅŸtÃ¼r (Faiss gereksinimi)
        embeddings = embeddings.astype('float32')
        
        if index_type == "flatl2":
            # L2 distance (Euclidean)
            self.index = faiss.IndexFlatL2(dim)
            
        elif index_type == "flatip":
            # Inner Product (normalize edilmiÅŸ vektÃ¶rler iÃ§in kosinÃ¼s benzerliÄŸi)
            self.index = faiss.IndexFlatIP(dim)
            
        elif index_type == "ivf":
            # IVF (Inverted File) - approximate search
            # BÃ¼yÃ¼k veri setleri iÃ§in daha hÄ±zlÄ± ama approximate
            nlist = min(100, n_samples // 10)  # Cluster sayÄ±sÄ±
            quantizer = faiss.IndexFlatL2(dim)
            self.index = faiss.IndexIVFFlat(quantizer, dim, nlist)
            
            # IVF indeksi training gerektirir
            print(f"   - Training IVF indeksi ({nlist} cluster)...")
            self.index.train(embeddings)
            self.is_trained = True
        
        else:
            raise ValueError(f"Desteklenmeyen indeks tipi: {index_type}")
        
        # VektÃ¶rleri indekse ekle
        self.index.add(embeddings)
        
        print(f"âœ“ Ä°ndeks oluÅŸturuldu. Toplam vektÃ¶r sayÄ±sÄ±: {self.index.ntotal}")
    
    def search(self, query_vector: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:
        """
        Query vektÃ¶rÃ¼ne en yakÄ±n k vektÃ¶rÃ¼ bulur
        
        Args:
            query_vector: (embedding_dim,) veya (1, embedding_dim) boyutunda query
            k: DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
            
        Returns:
            distances: (k,) boyutunda uzaklÄ±k/skor dizisi
            indices: (k,) boyutunda indeks dizisi
        """
        if self.index is None:
            raise RuntimeError("Ä°ndeks henÃ¼z oluÅŸturulmadÄ±! Ã–nce build_index() Ã§aÄŸÄ±rÄ±n.")
        
        # VektÃ¶r ÅŸeklini dÃ¼zenle
        if query_vector.ndim == 1:
            query_vector = query_vector.reshape(1, -1)
        
        # float32'ye dÃ¶nÃ¼ÅŸtÃ¼r
        query_vector = query_vector.astype('float32')
        
        # Arama yap
        k = min(k, self.index.ntotal)  # k, toplam vektÃ¶r sayÄ±sÄ±ndan fazla olamaz
        distances, indices = self.index.search(query_vector, k)
        
        return distances[0], indices[0]
    
    def search_batch(self, query_vectors: np.ndarray, 
                    k: int = 10) -> Tuple[np.ndarray, np.ndarray]:
        """
        Birden fazla query iÃ§in batch arama
        
        Args:
            query_vectors: (n_queries, embedding_dim) boyutunda query matrisi
            k: Her query iÃ§in dÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
            
        Returns:
            distances: (n_queries, k) boyutunda uzaklÄ±k matrisi
            indices: (n_queries, k) boyutunda indeks matrisi
        """
        if self.index is None:
            raise RuntimeError("Ä°ndeks henÃ¼z oluÅŸturulmadÄ±!")
        
        query_vectors = query_vectors.astype('float32')
        k = min(k, self.index.ntotal)
        
        distances, indices = self.index.search(query_vectors, k)
        return distances, indices
    
    def save_index(self, filepath: str):
        """Ä°ndeksi diske kaydet"""
        if self.index is None:
            raise RuntimeError("Kaydedilecek indeks yok!")
        
        faiss.write_index(self.index, filepath)
        print(f"âœ“ Faiss indeksi kaydedildi: {filepath}")
    
    def load_index(self, filepath: str):
        """Ä°ndeksi diskten yÃ¼kle"""
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Ä°ndeks dosyasÄ± bulunamadÄ±: {filepath}")
        
        self.index = faiss.read_index(filepath)
        print(f"âœ“ Faiss indeksi yÃ¼klendi: {filepath}")
        print(f"   - Toplam vektÃ¶r: {self.index.ntotal}")
    
    def get_index_size(self) -> int:
        """Ä°ndeksteki toplam vektÃ¶r sayÄ±sÄ±nÄ± dÃ¶ndÃ¼r"""
        return self.index.ntotal if self.index else 0


class VectorSearchEngine:
    """Ãœst seviye vektÃ¶r arama motoru - Faiss'i wrap eder"""
    
    def __init__(self, embedder_dim: int):
        """
        Args:
            embedder_dim: Embedding boyutu
        """
        self.faiss_search = FaissVectorSearch(embedder_dim)
        self.metadata = None  # Ä°lgili metadata (job_id, title, vb.)
    
    def index_documents(self, embeddings: np.ndarray, 
                       metadata: Dict = None,
                       index_type: str = "flatip"):
        """
        DÃ¶kÃ¼manlarÄ± indeksle
        
        Args:
            embeddings: DÃ¶kÃ¼man embedding'leri
            metadata: DÃ¶kÃ¼man metadata'sÄ± (opsiyonel)
            index_type: Faiss indeks tipi
        """
        self.faiss_search.build_index(embeddings, index_type=index_type)
        self.metadata = metadata
        
        if metadata:
            print(f"âœ“ {len(metadata)} dÃ¶kÃ¼man metadata'sÄ± kaydedildi")
    
    def search_similar(self, query_embedding: np.ndarray, 
                      k: int = 20) -> Tuple[List[int], List[float]]:
        """
        Benzer dÃ¶kÃ¼manlarÄ± ara
        
        Args:
            query_embedding: Query vektÃ¶rÃ¼
            k: DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
            
        Returns:
            indices: Bulunan dÃ¶kÃ¼man indeksleri
            scores: Benzerlik skorlarÄ±
        """
        distances, indices = self.faiss_search.search(query_embedding, k)
        
        # Inner Product (IP) indeksi kullanÄ±yorsak, skorlar zaten benzerlik
        # L2 kullanÄ±yorsak, uzaklÄ±ÄŸÄ± benzerliÄŸe Ã§evir
        scores = distances.tolist()
        
        return indices.tolist(), scores
    
    def save(self, index_path: str, metadata_path: str = None):
        """Arama motorunu kaydet"""
        self.faiss_search.save_index(index_path)
        
        if self.metadata and metadata_path:
            with open(metadata_path, 'wb') as f:
                pickle.dump(self.metadata, f)
            print(f"âœ“ Metadata kaydedildi: {metadata_path}")
    
    def load(self, index_path: str, metadata_path: str = None):
        """Arama motorunu yÃ¼kle"""
        self.faiss_search.load_index(index_path)
        
        if metadata_path and os.path.exists(metadata_path):
            with open(metadata_path, 'rb') as f:
                self.metadata = pickle.load(f)
            print(f"âœ“ Metadata yÃ¼klendi: {metadata_path}")


if __name__ == "__main__":
    # Test iÃ§in
    print("=" * 60)
    print("Faiss Vector Search Test")
    print("=" * 60)
    
    # Test verileri oluÅŸtur
    np.random.seed(42)
    embedding_dim = 384
    n_samples = 1000
    
    print(f"\nğŸ“Š Test verileri oluÅŸturuluyor...")
    print(f"   - VektÃ¶r boyutu: {embedding_dim}")
    print(f"   - VektÃ¶r sayÄ±sÄ±: {n_samples}")
    
    # Random embedding'ler oluÅŸtur ve normalize et
    embeddings = np.random.randn(n_samples, embedding_dim).astype('float32')
    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
    
    # Arama motoru oluÅŸtur
    search_engine = VectorSearchEngine(embedding_dim)
    search_engine.index_documents(embeddings, index_type="flatip")
    
    # Test query
    query = np.random.randn(embedding_dim).astype('float32')
    query = query / np.linalg.norm(query)
    
    print(f"\nğŸ” Arama yapÄ±lÄ±yor (k=10)...")
    indices, scores = search_engine.search_similar(query, k=10)
    
    print(f"\nâœ“ Top 10 sonuÃ§:")
    for i, (idx, score) in enumerate(zip(indices, scores), 1):
        print(f"   {i}. Ä°ndeks: {idx:4d} | Skor: {score:.4f}")
    
    print(f"\nâœ“ Test baÅŸarÄ±lÄ±!")